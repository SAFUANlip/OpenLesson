{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL7xnlhdt7UF"
      },
      "source": [
        "**In this task** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNuIeNCauwil"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HyXyB4iuztL"
      },
      "source": [
        "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
        "\n",
        "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for English and French languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OojQOHtutw_0",
        "outputId": "13da0484-9fe1-4c89-96ac-e76748b0584a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-22 21:22:33--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.249.141.9, 13.249.141.40, 13.249.141.108, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.249.141.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1325960915 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.en.300.vec.gz’\n",
            "\n",
            "cc.en.300.vec.gz    100%[===================>]   1.23G   183MB/s    in 7.0s    \n",
            "\n",
            "2023-04-22 21:22:40 (182 MB/s) - ‘cc.en.300.vec.gz’ saved [1325960915/1325960915]\n",
            "\n",
            "--2023-04-22 21:23:34--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.156.201.23, 108.156.201.129, 108.156.201.76, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.156.201.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1287757366 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.fr.300.vec.gz’\n",
            "\n",
            "cc.fr.300.vec.gz    100%[===================>]   1.20G  44.1MB/s    in 25s     \n",
            "\n",
            "2023-04-22 21:23:59 (49.9 MB/s) - ‘cc.fr.300.vec.gz’ saved [1287757366/1287757366]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
        "!gzip -d cc.en.300.vec.gz\n",
        "\n",
        "!wget -nc https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz\n",
        "!gzip -d cc.fr.300.vec.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI6K-PMfu9yl"
      },
      "source": [
        "After downloading and extracting the vectors, we should be able to load them using the [gensim](https://radimrehurek.com/gensim/) library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDMrMs6Xu2uM"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k_U2alqTvAP7"
      },
      "outputs": [],
      "source": [
        "en_emb = KeyedVectors.load_word2vec_format(\"cc.en.300.vec\")\n",
        "fr_emb = KeyedVectors.load_word2vec_format(\"cc.fr.300.vec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEO-Xrf7vKD0"
      },
      "source": [
        "Once you've loaded the vectors, you can use the `KeyedVectors` interface to get word embeddings and/or query most similar words by embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R8LuA1w0vKji",
        "outputId": "bff20ad7-d4cf-48dc-fabf-5a66f77b53c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((300,), array([-0.0522,  0.0364, -0.1252,  0.0053,  0.0382], dtype=float32))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "august_embedding = en_emb[\"august\"]\n",
        "august_embedding.shape, august_embedding[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zbb7G744vVT6",
        "outputId": "9ad7802a-8110-4af6-f654-f30d65c9c777"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('august', 0.9999999403953552),\n",
              " ('september', 0.8252838850021362),\n",
              " ('october', 0.8111193180084229),\n",
              " ('june', 0.8050147891044617),\n",
              " ('july', 0.797055184841156),\n",
              " ('november', 0.788363516330719),\n",
              " ('february', 0.7831973433494568),\n",
              " ('december', 0.7824540138244629),\n",
              " ('january', 0.7743154168128967),\n",
              " ('april', 0.7621643543243408)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_emb.most_similar([august_embedding], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuqF4uD5wPH6"
      },
      "source": [
        "Everything above is true for the embeddings for French language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FN1OutCsvgsy",
        "outputId": "8575981a-9437-4e53-c096-003c094e2682"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('aout', 1.0),\n",
              " ('Aout', 0.8249964118003845),\n",
              " ('juillet', 0.8109882473945618),\n",
              " ('fevrier', 0.8072442412376404),\n",
              " ('septembre', 0.7838520407676697),\n",
              " ('août', 0.779176652431488),\n",
              " ('juin', 0.7692081332206726),\n",
              " ('octobre', 0.7597455382347107),\n",
              " ('decembre', 0.7595790028572083),\n",
              " ('avril', 0.7390779256820679)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fr_emb.most_similar([fr_emb[\"aout\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KodwlCJNwalJ"
      },
      "source": [
        "However, french and english embeddings were trained independently of each other. This means, that there is no obvious connection between values in embeddings for similar words in French and English:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zxf2tWzIwbFZ",
        "outputId": "d7ead265-2888-4ab5-cb5d-4e48e25c53b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('2003Pays', 0.23082853853702545),\n",
              " ('Montsoriu', 0.22505579888820648),\n",
              " ('2015Pays', 0.22218400239944458),\n",
              " ('2013Genre', 0.2095685601234436),\n",
              " ('AdiCloud', 0.2018650770187378),\n",
              " ('Bagua', 0.20061466097831726),\n",
              " ('2003Paysans', 0.2001495361328125),\n",
              " ('ValenceLa', 0.2001476287841797),\n",
              " ('Luddites', 0.19998176395893097),\n",
              " ('Guadalquivir', 0.19875513017177582)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fr_emb.most_similar([en_emb[\"august\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lia_h7W2qL8C"
      },
      "source": [
        "## Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdYAR1q7uf6"
      },
      "source": [
        "We'll build a simple translator, which will try to predict the french embedding from the english one. For this we'll need a dataset of word pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CXbH86oQRprk"
      },
      "outputs": [],
      "source": [
        "def load_word_pairs(filename):\n",
        "    en_fr_pairs = []\n",
        "    en_vectors = []\n",
        "    fr_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            en, fr = line.rstrip().split(\" \")\n",
        "            if en not in en_emb or fr not in fr_emb:\n",
        "                continue\n",
        "            en_fr_pairs.append((en, fr))\n",
        "            en_vectors.append(en_emb[en])\n",
        "            fr_vectors.append(fr_emb[fr])\n",
        "    return en_fr_pairs, np.array(en_vectors), np.array(fr_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwjYGFE7Ui0N"
      },
      "source": [
        "We will train our model to predict embedding for the french word from embedding of its english counterpart. For this reason we split our train and test data into english and french words and compute corresponding embeddings to obtain `X` (english embeddings) and `y` (french embeddings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPvHHq7Cc_Oa"
      },
      "outputs": [],
      "source": [
        "!wget -O en-fr.train.txt https://raw.githubusercontent.com/girafe-ai/ml-course/23s_nes/homeworks/hw04_umt/en-fr.train.txt\n",
        "!wget -O en-fr.test.txt https://raw.githubusercontent.com/girafe-ai/ml-course/23s_nes/homeworks/hw04_umt/en-fr.test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX5bQppexXP4"
      },
      "outputs": [],
      "source": [
        "en_fr_train, X_train, Y_train = load_word_pairs(\"en-fr.train.txt\")\n",
        "en_fr_test, X_test, Y_test = load_word_pairs(\"en-fr.test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nC1eC_wxeb4"
      },
      "outputs": [],
      "source": [
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z3crTrkxgHY"
      },
      "outputs": [],
      "source": [
        "en_fr_train[33:44]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dhk5gL7ugS"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called [Procrustes problem](https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem):\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n\\|Wx_i - y_i\\|_2$$\n",
        "\n",
        "or\n",
        "\n",
        "$$W^*= \\arg\\min_W \\|XW^T - Y\\|_F$$\n",
        "\n",
        "where $\\|\\cdot\\|_F$ denotes Frobenius norm.\n",
        "\n",
        "> **Note:** in second formula, $W$ and $x$ seem to have switched places. This happens because the $X$ matrix is composed of objects $x_i$ in *rows* not *columns*, i.e. it is kind of composed of $x_i^T$. This means that $X \\in \\mathbb{R}^{N \\times D}$, where $N$ is the number of items and $D$ is the embedding dimensionality. The same is true for the $Y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOjDdtL7ugY"
      },
      "source": [
        "$W^*= \\arg\\min_W \\sum_{i=1}^n\\|Wx_i - y_i\\|_2$ looks like simple multiple linear regression without bias. The `sklearn` allows you to turn off the bias in `LinearRegression` via the `fit_intercept` argument (in fact they simply call bias the intercept). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLvaZjV8xicQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "mapping = LinearRegression(fit_intercept=True).fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VVE3AK6ywIR"
      },
      "outputs": [],
      "source": [
        "mapping.intercept_.shape "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tqJwoY7ugf"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"august\"_ (_\"aout\"_ in French) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FUnPwapx9D5"
      },
      "outputs": [],
      "source": [
        "august_dot = mapping.coef_ @ en_emb[\"august\"] + mapping.intercept_  #.reshape(1, -1)\n",
        "fr_emb.most_similar(august_dot, topn=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCEOwBOgye8R"
      },
      "outputs": [],
      "source": [
        "august = mapping.predict(en_emb[\"august\"].reshape(1, -1))\n",
        "fr_emb.most_similar(august, topn=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnNxqhcxzHPq"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tk = WordPunctTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pW536u-eypav"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in English (str)\n",
        "    :returns:\n",
        "        translation - sentence in French (str)\n",
        "\n",
        "    * find english embedding for each word in sentence\n",
        "    * transform english embedding vector\n",
        "    * find nearest french word and replace\n",
        "    \"\"\"\n",
        "    tokens = tk.tokenize(sentence)\n",
        "    # your_code here\n",
        "    \n",
        "\n",
        "    return \" \".join(translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAHKI3XAzCAX"
      },
      "outputs": [],
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"I walk around Paris\") == \"je marcher autour Paris\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8BHh2OszJGQ"
      },
      "outputs": [],
      "source": [
        "translate(\"I walk around Paris hhahahahah\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbck1tCFzaan"
      },
      "outputs": [],
      "source": [
        "tk.tokenize(\"I walk ., around Paris hhahahahah\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Dq_zX-IzsuO"
      },
      "outputs": [],
      "source": [
        "en_emb[tk.tokenize(\"I walk ., around Paris hhahahahah\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE_-3hBE0DD3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}